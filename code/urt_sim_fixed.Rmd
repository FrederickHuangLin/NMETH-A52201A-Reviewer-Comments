---
title: "Simulations for Fixed Effects Models: Upper Respiratory Tract Microbiome Data (5 iterations)"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document: 
    toc: true
    theme: united
---

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, 
                      message = FALSE, comment = NA,
                      fig.width = 6.25, fig.height = 5)
library(openxlsx)
library(tidyverse)
library(mia)
library(ggpubr)
library(doRNG)
library(doParallel)
# Please make sure your Bioconductor version is 3.17 to install the latest ANCOMBC package (version 2.2.1)
# Otherwise, try 
# devtools::install_github("FrederickHuangLin/ANCOMBC", ref = "RELEASE_3_17")
library(ANCOMBC)
library(corncob)
library(MicrobiomeStat)
library(LOCOM)
```

```{r helper}
logsumexp = function (x) {
  y = max(x)
  y + log(sum(exp(x - y)))
}

softmax = function (x) {
  exp(x - logsumexp(x))
}

wb = createWorkbook()
```

# Test for a binary exposure {.tabset}

1 binary exposure + 1 continuous confounder

```{r}
# Simulation settings
data(throat.otu.table, package = "LOCOM")
# Use the URT data as the template to obtain mean vector and variance-covariance
# matrix. Discard OTUs that have less than 5% of prevalence across samples
prevalence = apply(t(throat.otu.table), 1, function(x)
  sum(x != 0, na.rm = TRUE)/length(x[!is.na(x)]))
tax_keep = which(prevalence >= 0.05)

set.seed(12345)
n = c(20, 40, 60, 100, 200)
d = length(tax_keep)
diff_prop = c(0.05, 0.2, 0.9)
iter_num = 5
seed = seq_len(iter_num)
df_sim_params = data.frame(expand.grid(n, diff_prop, seed)) %>%
  dplyr::rename(n = Var1, diff_prop = Var2, seed = Var3) %>%
  arrange(n, diff_prop, seed)
list_sim_params = apply(df_sim_params, 1, paste0, collapse = "_")

# Log-fold-changes for the binary exposure of DA taxa
lfc_value = c(-2, -1, 1, 2)
lfc_bin_list = vector("list", length = length(diff_prop))
for (i in seq_along(diff_prop)) {
  lfc_bin_list[[i]] = sample(c(0, lfc_value), size = d, replace = TRUE,
                             prob = c(1 - diff_prop[i], 
                                      rep(diff_prop[i]/length(lfc_value), length(lfc_value))))
}
names(lfc_bin_list) = diff_prop

# Log-fold-changes for the continuous confounder
lfc_cont_list = vector("list", length = length(diff_prop))
for (i in seq_along(diff_prop)) {
  lfc_cont_list[[i]] = sample(c(0, 1), size = d, replace = TRUE,
                              prob = c(1 - diff_prop[i], diff_prop[i]))
}
names(lfc_cont_list) = diff_prop

parallel::detectCores()
```

Kindly take note that, in the subsequent code segment, we have set the `eval` parameter to `FALSE` to optimize the knitting time of the Rmarkdown file. If computational efficiency is not a limiting factor on your machine, you may opt to remove this setting. It is essential to acknowledge that parallel computing on various machines can yield slightly varying results. Consequently, running only five iterations may not be a truly equitable basis for comparing different methods. The code primarily serves as a demonstrative example. Should you wish to replicate the results outlined in the paper, albeit with minor discrepancies arising from machine-specific differences, please feel free to increase the iteration count to 100.

## ANCOM-BC2

```{r, eval=FALSE}
cl = makeCluster(8)
registerDoParallel(cl)

res_sim = foreach(i = list_sim_params, .combine = rbind, .verbose = TRUE, 
                  .packages = c("ANCOMBC", "tidyverse")) %dorng% 
  {
    params = strsplit(i, "_")[[1]]
    n = as.numeric(params[1])
    diff_prop = as.numeric(params[2])
    seed = as.numeric(params[3])
    
    # Generate the true abundances
    set.seed(seed)
    abn_data = sim_plnm(abn_table = throat.otu.table, taxa_are_rows = FALSE, 
                        prv_cut = 0.05, n = n, lib_mean = 1e8, disp = 0.5)
    log_abn_data = log(abn_data + 1e-5)
    rownames(log_abn_data) = paste0("T", seq_len(d))
    colnames(log_abn_data) = paste0("S", seq_len(n))
    
    # Generate the sample and feature meta data
    # Sampling fractions are set to differ by the variable of interest
    smd = data.frame(sample = paste0("S", seq_len(n)),
                     samp_frac = log(c(runif(n/2, min = 1e-4, max = 1e-3),
                                       runif(n/2, min = 1e-3, max = 1e-2))),
                     cont_cov = rnorm(n),
                     bin_cov = as.factor(rep(seq_len(2), each = n/2)))
    
    d = nrow(abn_data) 
    lfc_bin = lfc_bin_list[[as.character(diff_prop)]]
    lfc_cont = lfc_cont_list[[as.character(diff_prop)]]
    fmd = data.frame(taxon = paste0("T", seq_len(d)),
                     seq_eff = log(runif(d, min = 0.1, max = 1)),
                     lfc_cont = lfc_cont,
                     lfc_bin = lfc_bin)
    
    # Add effect sizes of covariates to the true abundances
    smd_dmy = model.matrix(~ 0 + cont_cov + bin_cov, data = smd)
    log_abn_data = log_abn_data + outer(fmd$lfc_cont, smd_dmy[, "cont_cov"] )
    log_abn_data = log_abn_data + outer(fmd$lfc_bin, smd_dmy[, "bin_cov2"])
    
    # Add sample- and taxon-specific biases
    log_otu_data = t(t(log_abn_data) + smd$samp_frac)
    log_otu_data = log_otu_data + fmd$seq_eff
    otu_data = round(exp(log_otu_data))
    
    # Create the tse object
    assays = S4Vectors::SimpleList(counts = otu_data)
    smd = S4Vectors::DataFrame(smd)
    tse = TreeSummarizedExperiment::TreeSummarizedExperiment(assays = assays, colData = smd)
    
    # Run ANCOM-BC2
    set.seed(123)
    output = ancombc2(data = tse, assay_name = "counts", tax_level = NULL,
                      fix_formula = "cont_cov + bin_cov", rand_formula = NULL,
                      p_adj_method = "holm", 
                      prv_cut = 0.10, lib_cut = 1000, s0_perc = 0.05,
                      group = "bin_cov", struc_zero = FALSE, neg_lb = FALSE,
                      alpha = 0.05, n_cl = 1, verbose = FALSE,
                      global = FALSE, pairwise = FALSE, 
                      dunnet = FALSE, trend = FALSE,
                      iter_control = list(tol = 1e-5, max_iter = 20, 
                                          verbose = FALSE),
                      em_control = list(tol = 1e-5, max_iter = 100),
                      lme_control = NULL, mdfdr_control = NULL, 
                      trend_control = NULL)
    
    res_prim = output$res
    res_merge1 = res_prim %>%
      dplyr::transmute(taxon, lfc_est = lfc_bin_cov2 * diff_bin_cov2) %>%
      dplyr::left_join(fmd %>%
                         dplyr::transmute(taxon, lfc_true = lfc_bin),
                       by = "taxon") %>%
      dplyr::transmute(taxon, 
                       lfc_est = case_when(lfc_est > 0 ~ 1,
                                           lfc_est < 0 ~ -1,
                                           TRUE ~ 0),
                       lfc_true = case_when(lfc_true > 0 ~ 1,
                                            lfc_true < 0 ~ -1,
                                            TRUE ~ 0))
    res_merge2 = res_prim %>%
      dplyr::transmute(taxon, lfc_est = lfc_bin_cov2 * diff_bin_cov2 * passed_ss_bin_cov2) %>%
      dplyr::left_join(fmd %>%
                         dplyr::transmute(taxon, lfc_true = lfc_bin),
                       by = "taxon") %>%
      dplyr::transmute(taxon, 
                       lfc_est = case_when(lfc_est > 0 ~ 1,
                                           lfc_est < 0 ~ -1,
                                           TRUE ~ 0),
                       lfc_true = case_when(lfc_true > 0 ~ 1,
                                            lfc_true < 0 ~ -1,
                                            TRUE ~ 0))
    lfc_est = res_merge1$lfc_est
    lfc_true = res_merge1$lfc_true
    tp = sum(lfc_true != 0 & lfc_est != 0)
    fp = sum(lfc_true == 0 & lfc_est != 0)
    fn = sum(lfc_true != 0 & lfc_est == 0)
    power1 = tp/(tp + fn)
    fdr1 = fp/(tp + fp)
    
    lfc_est = res_merge2$lfc_est
    lfc_true = res_merge2$lfc_true
    tp = sum(lfc_true != 0 & lfc_est != 0)
    fp = sum(lfc_true == 0 & lfc_est != 0)
    fn = sum(lfc_true != 0 & lfc_est == 0)
    power2 = tp/(tp + fn)
    fdr2 = fp/(tp + fp)
    
    c(power1, fdr1, power2, fdr2)
  }

stopCluster(cl)

write_csv(data.frame(res_sim), "../data/urt_sim_bin_ancombc2.csv")
```

## ANCOM-BC

```{r, eval=FALSE}
cl = makeCluster(8)
registerDoParallel(cl)

res_sim = foreach(i = list_sim_params, .combine = rbind, .verbose = TRUE, 
                  .packages = c("ANCOMBC", "tidyverse")) %dorng% 
  {
    params = strsplit(i, "_")[[1]]
    n = as.numeric(params[1])
    diff_prop = as.numeric(params[2])
    seed = as.numeric(params[3])
    
    # Generate the true abundances
    set.seed(seed)
    abn_data = sim_plnm(abn_table = throat.otu.table, taxa_are_rows = FALSE, 
                        prv_cut = 0.05, n = n, lib_mean = 1e8, disp = 0.5)
    log_abn_data = log(abn_data + 1e-5)
    rownames(log_abn_data) = paste0("T", seq_len(d))
    colnames(log_abn_data) = paste0("S", seq_len(n))
    
    # Generate the sample and feature meta data
    # Sampling fractions are set to differ by the variable of interest
    smd = data.frame(sample = paste0("S", seq_len(n)),
                     samp_frac = log(c(runif(n/2, min = 1e-4, max = 1e-3),
                                       runif(n/2, min = 1e-3, max = 1e-2))),
                     cont_cov = rnorm(n),
                     bin_cov = as.factor(rep(seq_len(2), each = n/2)))
    
    d = nrow(abn_data) 
    lfc_bin = lfc_bin_list[[as.character(diff_prop)]]
    lfc_cont = lfc_cont_list[[as.character(diff_prop)]]
    fmd = data.frame(taxon = paste0("T", seq_len(d)),
                     seq_eff = log(runif(d, min = 0.1, max = 1)),
                     lfc_cont = lfc_cont,
                     lfc_bin = lfc_bin)
    
    # Add effect sizes of covariates to the true abundances
    smd_dmy = model.matrix(~ 0 + cont_cov + bin_cov, data = smd)
    log_abn_data = log_abn_data + outer(fmd$lfc_cont, smd_dmy[, "cont_cov"] )
    log_abn_data = log_abn_data + outer(fmd$lfc_bin, smd_dmy[, "bin_cov2"])
    
    # Add sample- and taxon-specific biases
    log_otu_data = t(t(log_abn_data) + smd$samp_frac)
    log_otu_data = log_otu_data + fmd$seq_eff
    otu_data = round(exp(log_otu_data))
    
    # Create the tse object
    assays = S4Vectors::SimpleList(counts = otu_data)
    smd = S4Vectors::DataFrame(smd)
    tse = TreeSummarizedExperiment::TreeSummarizedExperiment(assays = assays, colData = smd)
    
    # Run ANCOM-BC2
    set.seed(123)
    output = ancombc(data = tse, assay_name = "counts", 
                     tax_level = NULL, phyloseq = NULL, 
                     formula = "cont_cov + bin_cov", 
                     p_adj_method = "holm", prv_cut = 0.10, lib_cut = 1000, 
                     group = "bin_cov", struc_zero = FALSE, neg_lb = FALSE, tol = 1e-5, 
                     max_iter = 100, conserve = TRUE, alpha = 0.05, global = FALSE,
                     n_cl = 1, verbose = FALSE)
    
    res_prim = output$res
    res_merge = res_prim$lfc %>%
      dplyr::transmute(taxon, lfc_est = bin_cov2) %>%
      dplyr::left_join(res_prim$diff_abn %>%
                         dplyr::transmute(taxon, diff = bin_cov2),
                       by = "taxon") %>%
      dplyr::left_join(fmd %>%
                         dplyr::transmute(taxon, lfc_true = lfc_bin),
                       by = "taxon") %>%
      dplyr::transmute(taxon, 
                       lfc_est = lfc_est * diff,
                       lfc_est = case_when(lfc_est > 0 ~ 1,
                                           lfc_est < 0 ~ -1,
                                           TRUE ~ 0),
                       lfc_true = case_when(lfc_true > 0 ~ 1,
                                            lfc_true < 0 ~ -1,
                                            TRUE ~ 0))
    lfc_est = res_merge$lfc_est
    lfc_true = res_merge$lfc_true
    tp = sum(lfc_true != 0 & lfc_est != 0)
    fp = sum(lfc_true == 0 & lfc_est != 0)
    fn = sum(lfc_true != 0 & lfc_est == 0)
    power = tp/(tp + fn)
    fdr = fp/(tp + fp)
    
    c(power, fdr)
  }

stopCluster(cl)

write_csv(data.frame(res_sim), "../data/urt_sim_bin_ancombc.csv")
```

## CORNCOB

```{r, eval=FALSE}
cl = makeCluster(8)
registerDoParallel(cl)

res_sim = foreach(i = list_sim_params, .combine = rbind, .verbose = TRUE, 
                  .packages = c("ANCOMBC", "corncob", "tidyverse", "microbiome")) %dorng% 
  {
    params = strsplit(i, "_")[[1]]
    n = as.numeric(params[1])
    diff_prop = as.numeric(params[2])
    seed = as.numeric(params[3])
    
    # Generate the true abundances
    set.seed(seed)
    abn_data = sim_plnm(abn_table = throat.otu.table, taxa_are_rows = FALSE, 
                        prv_cut = 0.05, n = n, lib_mean = 1e8, disp = 0.5)
    log_abn_data = log(abn_data + 1e-5)
    rownames(log_abn_data) = paste0("T", seq_len(d))
    colnames(log_abn_data) = paste0("S", seq_len(n))
    
    # Generate the sample and feature meta data
    # Sampling fractions are set to differ by the variable of interest
    smd = data.frame(sample = paste0("S", seq_len(n)),
                     samp_frac = log(c(runif(n/2, min = 1e-4, max = 1e-3),
                                       runif(n/2, min = 1e-3, max = 1e-2))),
                     cont_cov = rnorm(n),
                     bin_cov = as.factor(rep(seq_len(2), each = n/2)))
    
    d = nrow(abn_data) 
    lfc_bin = lfc_bin_list[[as.character(diff_prop)]]
    lfc_cont = lfc_cont_list[[as.character(diff_prop)]]
    fmd = data.frame(taxon = paste0("T", seq_len(d)),
                     seq_eff = log(runif(d, min = 0.1, max = 1)),
                     lfc_cont = lfc_cont,
                     lfc_bin = lfc_bin)
    
    # Add effect sizes of covariates to the true abundances
    smd_dmy = model.matrix(~ 0 + cont_cov + bin_cov, data = smd)
    log_abn_data = log_abn_data + outer(fmd$lfc_cont, smd_dmy[, "cont_cov"] )
    log_abn_data = log_abn_data + outer(fmd$lfc_bin, smd_dmy[, "bin_cov2"])
    
    # Add sample- and taxon-specific biases
    log_otu_data = t(t(log_abn_data) + smd$samp_frac)
    log_otu_data = log_otu_data + fmd$seq_eff
    otu_data = round(exp(log_otu_data))
    
    # Remove samples with low library sizes
    idx = which(colSums(otu_data) > 1000)
    otu_data = otu_data[, idx]
    smd = smd[idx, ]
    
    # Crease the phyloseq object
    OTU = otu_table(otu_data, taxa_are_rows = TRUE)
    META = sample_data(smd)
    sample_names(META) = smd$sample
    pseq = phyloseq(OTU, META)
    
    # Run corncob
    output = differentialTest(formula = ~ cont_cov + bin_cov,
                              phi.formula = ~ cont_cov + bin_cov,
                              formula_null = ~ cont_cov,
                              phi.formula_null = ~ cont_cov + bin_cov,
                              test = "Wald", boot = FALSE,
                              data = pseq,
                              fdr = "holm",
                              fdr_cutoff = 0.05)
    
    res = data.frame(taxon = output$significant_taxa,
                     sig_est = 1)
    res_merge = fmd %>%
      dplyr::transmute(taxon, sig_true = ifelse(lfc_bin != 0, 1, 0)) %>%
      dplyr::left_join(
        res, by = "taxon"
      ) %>%
      replace_na(list(sig_est = 0))
    
    sig_est = res_merge$sig_est
    sig_true = res_merge$sig_true
    tp = sum(sig_true != 0 & sig_est != 0)
    fp = sum(sig_true == 0 & sig_est != 0)
    fn = sum(sig_true != 0 & sig_est == 0)
    power = tp/(tp + fn)
    fdr = fp/(tp + fp)
    
    c(power, fdr)
  }

stopCluster(cl)

write_csv(data.frame(res_sim), "../data/urt_sim_bin_corncob.csv")
```

## LinDA

```{r, eval=FALSE}
cl = makeCluster(8)
registerDoParallel(cl)

res_sim = foreach(i = list_sim_params, .combine = rbind, .verbose = TRUE, 
                  .packages = c("ANCOMBC", "MicrobiomeStat", "tidyverse")) %dorng% 
  {
    params = strsplit(i, "_")[[1]]
    n = as.numeric(params[1])
    diff_prop = as.numeric(params[2])
    seed = as.numeric(params[3])
    
    # Generate the true abundances
    set.seed(seed)
    abn_data = sim_plnm(abn_table = throat.otu.table, taxa_are_rows = FALSE, 
                        prv_cut = 0.05, n = n, lib_mean = 1e8, disp = 0.5)
    log_abn_data = log(abn_data + 1e-5)
    rownames(log_abn_data) = paste0("T", seq_len(d))
    colnames(log_abn_data) = paste0("S", seq_len(n))
    
    # Generate the sample and feature meta data
    # Sampling fractions are set to differ by the variable of interest
    smd = data.frame(sample = paste0("S", seq_len(n)),
                     samp_frac = log(c(runif(n/2, min = 1e-4, max = 1e-3),
                                       runif(n/2, min = 1e-3, max = 1e-2))),
                     cont_cov = rnorm(n),
                     bin_cov = as.factor(rep(seq_len(2), each = n/2)))
    
    d = nrow(abn_data) 
    lfc_bin = lfc_bin_list[[as.character(diff_prop)]]
    lfc_cont = lfc_cont_list[[as.character(diff_prop)]]
    fmd = data.frame(taxon = paste0("T", seq_len(d)),
                     seq_eff = log(runif(d, min = 0.1, max = 1)),
                     lfc_cont = lfc_cont,
                     lfc_bin = lfc_bin)
    
    # Add effect sizes of covariates to the true abundances
    smd_dmy = model.matrix(~ 0 + cont_cov + bin_cov, data = smd)
    log_abn_data = log_abn_data + outer(fmd$lfc_cont, smd_dmy[, "cont_cov"] )
    log_abn_data = log_abn_data + outer(fmd$lfc_bin, smd_dmy[, "bin_cov2"])
    
    # Add sample- and taxon-specific biases
    log_otu_data = t(t(log_abn_data) + smd$samp_frac)
    log_otu_data = log_otu_data + fmd$seq_eff
    otu_data = round(exp(log_otu_data))
    
    # Remove samples with low library sizes
    idx = which(colSums(otu_data) > 1000)
    otu_data = otu_data[, idx]
    smd = smd[idx, ]
    
    # Run LinDA
    output = linda(feature.dat = otu_data, meta.dat = smd,
                   formula = "~ cont_cov + bin_cov",
                   alpha = 0.05, 
                   prev.filter = 0.10, 
                   mean.abund.filter = 0,
                   adaptive = TRUE,
                   max.abund.filter = 0,
                   p.adj.method = "holm",
                   n.cores = 1, 
                   verbose = FALSE)
    
    res = output$output
    res_merge = res$bin_cov2 %>%
      rownames_to_column("taxon") %>%
      dplyr::transmute(taxon, lfc_est = log2FoldChange * reject) %>%
      dplyr::left_join(fmd %>%
                         dplyr::transmute(taxon, lfc_true = lfc_bin),
                       by = "taxon") %>%
      dplyr::transmute(taxon, 
                       lfc_est = case_when(lfc_est > 0 ~ 1,
                                           lfc_est < 0 ~ -1,
                                           TRUE ~ 0),
                       lfc_true = case_when(lfc_true > 0 ~ 1,
                                            lfc_true < 0 ~ -1,
                                            TRUE ~ 0))
    lfc_est = res_merge$lfc_est
    lfc_true = res_merge$lfc_true
    tp = sum(lfc_true != 0 & lfc_est != 0)
    fp = sum(lfc_true == 0 & lfc_est != 0)
    fn = sum(lfc_true != 0 & lfc_est == 0)
    power = tp/(tp + fn)
    fdr = fp/(tp + fp)
    
    c(power, fdr)
  }

stopCluster(cl)

write_csv(data.frame(res_sim), "../data/urt_sim_bin_linda.csv")
```

## LOCOM

```{r, eval=FALSE}
cl = makeCluster(8)
registerDoParallel(cl)

res_sim = foreach(i = list_sim_params, .combine = rbind, .verbose = TRUE, 
                  .packages = c("ANCOMBC", "LOCOM", "tidyverse")) %dorng% 
  {
    params = strsplit(i, "_")[[1]]
    n = as.numeric(params[1])
    diff_prop = as.numeric(params[2])
    seed = as.numeric(params[3])
    
    # Generate the true abundances
    set.seed(seed)
    abn_data = sim_plnm(abn_table = throat.otu.table, taxa_are_rows = FALSE, 
                        prv_cut = 0.05, n = n, lib_mean = 1e8, disp = 0.5)
    log_abn_data = log(abn_data + 1e-5)
    rownames(log_abn_data) = paste0("T", seq_len(d))
    colnames(log_abn_data) = paste0("S", seq_len(n))
    
    # Generate the sample and feature meta data
    # Sampling fractions are set to differ by the variable of interest
    smd = data.frame(sample = paste0("S", seq_len(n)),
                     samp_frac = log(c(runif(n/2, min = 1e-4, max = 1e-3),
                                       runif(n/2, min = 1e-3, max = 1e-2))),
                     cont_cov = rnorm(n),
                     bin_cov = as.factor(rep(seq_len(2), each = n/2)))
    
    d = nrow(abn_data) 
    lfc_bin = lfc_bin_list[[as.character(diff_prop)]]
    lfc_cont = lfc_cont_list[[as.character(diff_prop)]]
    fmd = data.frame(taxon = paste0("T", seq_len(d)),
                     seq_eff = log(runif(d, min = 0.1, max = 1)),
                     lfc_cont = lfc_cont,
                     lfc_bin = lfc_bin)
    
    # Add effect sizes of covariates to the true abundances
    smd_dmy = model.matrix(~ 0 + cont_cov + bin_cov, data = smd)
    log_abn_data = log_abn_data + outer(fmd$lfc_cont, smd_dmy[, "cont_cov"] )
    log_abn_data = log_abn_data + outer(fmd$lfc_bin, smd_dmy[, "bin_cov2"])
    
    # Add sample- and taxon-specific biases
    log_otu_data = t(t(log_abn_data) + smd$samp_frac)
    log_otu_data = log_otu_data + fmd$seq_eff
    otu_data = round(exp(log_otu_data))
    
    # Remove samples with low library sizes
    idx = which(colSums(otu_data) > 1000)
    otu_data = otu_data[, idx]
    smd = smd[idx, ]
    
    otu_table = data.matrix(t(otu_data))
    Y = smd$bin_cov
    C = data.matrix(model.matrix(Y ~ smd$cont_cov - 1))
    
    # Run LOCOM
    suppressWarnings(output <- try(locom(otu.table = otu_table, 
                                         Y = Y, 
                                         C = C, 
                                         fdr.nominal = 0.05, 
                                         prev.cut = 0.1,
                                         seed = 123, 
                                         adjustment = "holm", 
                                         n.cores = 1),
                                   silent = TRUE))
    if (inherits(output, "try-error")) {
      power = NA; fdr = NA
    }else{
      res = data.frame(taxon = colnames(output$p.otu),
                       lfc_est = as.numeric(signif(output$effect.size, 3)),
                       q_value = as.numeric(signif(output$q.otu, 3)),
                       row.names = NULL)
      res_merge = res %>%
        dplyr::transmute(taxon, lfc_est = lfc_est * (q_value < 0.05)) %>%
        dplyr::left_join(fmd %>%
                           dplyr::transmute(taxon, lfc_true = lfc_bin),
                         by = "taxon") %>%
        dplyr::transmute(taxon, 
                         lfc_est = case_when(lfc_est > 0 ~ 1,
                                             lfc_est < 0 ~ -1,
                                             TRUE ~ 0),
                         lfc_true = case_when(lfc_true > 0 ~ 1,
                                              lfc_true < 0 ~ -1,
                                              TRUE ~ 0))
      lfc_est = res_merge$lfc_est
      lfc_true = res_merge$lfc_true
      tp = sum(lfc_true != 0 & lfc_est != 0)
      fp = sum(lfc_true == 0 & lfc_est != 0)
      fn = sum(lfc_true != 0 & lfc_est == 0)
      power = tp/(tp + fn)
      fdr = fp/(tp + fp)
    }
    c(power, fdr)
  }

stopCluster(cl)

write_csv(data.frame(res_sim), "../data/urt_sim_bin_locom.csv")
```

## Visualization

```{r, fig.width=10, fig.height=8}
df_ancombc2 = read_csv("../data/urt_sim_bin_ancombc2.csv")
df_ancombc = read_csv("../data/urt_sim_bin_ancombc.csv")
df_corncob = read_csv("../data/urt_sim_bin_corncob.csv")
df_linda = read_csv("../data/urt_sim_bin_linda.csv")
df_locom = read_csv("../data/urt_sim_bin_locom.csv")

simpattern = distinct(df_sim_params, n, diff_prop) %>%
  unite("setting", n:diff_prop, sep = ", ")

df_ancombc2_no_filter = df_ancombc2 %>%
  dplyr::select(X1, X2) %>%
  mutate(method = "ANCOM-BC2 (No Filter)",
         setting = rep(simpattern$setting, each = iter_num))
df_ancombc2_ss_filter = df_ancombc2 %>%
  dplyr::transmute(X1 = X3, X2 = X4) %>%
  mutate(method = "ANCOM-BC2 (SS Filter)",
         setting = rep(simpattern$setting, each = iter_num))
df_ancombc = df_ancombc %>%
  mutate(method = "ANCOM-BC",
         setting = rep(simpattern$setting, each = iter_num))
df_corncob = df_corncob %>%
  mutate(method = "CORNCOB",
         setting = rep(simpattern$setting, each = iter_num))
df_linda = df_linda %>%
  mutate(method = "LinDA",
         setting = rep(simpattern$setting, each = iter_num))
df_locom = df_locom %>%
  mutate(method = "LOCOM",
         setting = rep(simpattern$setting, each = iter_num))

df_fig = df_ancombc2_no_filter %>%
  bind_rows(df_ancombc2_ss_filter) %>%
  bind_rows(df_ancombc) %>%
  bind_rows(df_corncob) %>%
  bind_rows(df_linda) %>%
  bind_rows(df_locom) %>%
  separate(setting, c("n", "diff_prop"), ", ") %>%
  mutate(X1 = replace_na(X1, 0),
         X2 = replace_na(X2, 0))
df_fig$method = factor(df_fig$method, 
                       levels = c("ANCOM-BC2 (No Filter)", "ANCOM-BC2 (SS Filter)", 
                                  "ANCOM-BC", "CORNCOB", "LinDA", "LOCOM"))

fig_power_bin = df_fig %>%
  ggline(x = "n", y = "X1", add = "mean_se",
         color = "method", palette = "npg",
         xlab = "Sample Size", ylab = "Power", 
         facet.by = "diff_prop", nrow = 1,
         size = 0.2, point.size = 0.1) +
  scale_x_discrete(labels = c(10, 20, 30, 50, 100)) +
  guides(color = guide_legend(title = NULL))

fig_fdr_bin = df_fig %>%
  ggline(x = "n", y = "X2", add = "mean_se",
         color = "method", palette = "npg",
         xlab = "Sample Size", ylab = "FDR", 
         facet.by = "diff_prop", nrow = 1,
         size = 0.2, point.size = 0.1) +
  scale_x_discrete(labels = c(10, 20, 30, 50, 100)) +
  guides(color = guide_legend(title = NULL)) +
  geom_hline(yintercept = 0.05, linetype = "dashed")

fig_bin = ggarrange(fig_fdr_bin, fig_power_bin, 
                    ncol = 1, common.legend = TRUE)

fig_bin
```

## Summary

```{r}
df_tab = df_fig
df_tab$n = as.numeric(df_tab$n)

tab = df_tab %>% 
  dplyr::transmute(method = method, n = n,
                   power = ifelse(X1 == 0, 1e-5, X1),
                   fdr = case_when(
                     X2 == 0 ~ 1e-5, 
                     is.na(X2) ~ 0,
                     TRUE ~ X2
                   ),
                   fap = log(power/fdr)) %>%
  group_by(method, n) %>% 
  summarise(power_mean = round(mean(power, na.rm = TRUE), 2),
            power_sd = round(sd(power, na.rm = TRUE), 2),
            fdr_mean = round(mean(fdr, na.rm = TRUE), 2),
            fdr_sd = round(sd(fdr, na.rm = TRUE), 2),
            fap_mean = round(mean(fap, na.rm = TRUE), 2),
            fap_sd = round(sd(fdr, na.rm = TRUE), 2)) %>%
  arrange(n, method) %>%
  mutate(power = paste0(power_mean, " (", power_sd, ")"),
         fdr = paste0(fdr_mean, " (", fdr_sd, ")"),
         fap = paste0(fap_mean, " (", fap_sd, ")")) %>%
  dplyr::select(method, n, power, fdr, fap)

tab
```

# Session information

```{r, message = FALSE, warning = FALSE, comment = NA}
sessionInfo()
```









